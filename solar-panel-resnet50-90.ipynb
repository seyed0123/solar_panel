{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-26T18:23:59.935497Z",
     "iopub.status.busy": "2025-07-26T18:23:59.935260Z",
     "iopub.status.idle": "2025-07-26T18:24:00.188108Z",
     "shell.execute_reply": "2025-07-26T18:24:00.187586Z",
     "shell.execute_reply.started": "2025-07-26T18:23:59.935479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:00.189673Z",
     "iopub.status.busy": "2025-07-26T18:24:00.189332Z",
     "iopub.status.idle": "2025-07-26T18:24:01.099753Z",
     "shell.execute_reply": "2025-07-26T18:24:01.099144Z",
     "shell.execute_reply.started": "2025-07-26T18:24:00.189655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:01.100711Z",
     "iopub.status.busy": "2025-07-26T18:24:01.100447Z",
     "iopub.status.idle": "2025-07-26T18:24:02.185695Z",
     "shell.execute_reply": "2025-07-26T18:24:02.184962Z",
     "shell.execute_reply.started": "2025-07-26T18:24:01.100695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = \"/kaggle/input/solar-panel-images/Faulty_solar_panel/\"\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "class_names = []\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        class_names.append(class_name)\n",
    "        image_count = 0\n",
    "        for root, dirs, files in os.walk(class_path):\n",
    "            image_count += sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "        class_counts[class_name] = image_count\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.title('Image Count per Class (Recursive)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:02.186555Z",
     "iopub.status.busy": "2025-07-26T18:24:02.186379Z",
     "iopub.status.idle": "2025-07-26T18:24:04.216921Z",
     "shell.execute_reply": "2025-07-26T18:24:04.216241Z",
     "shell.execute_reply.started": "2025-07-26T18:24:02.186540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_all_images_in_class(cls_path):\n",
    "    valid_ext = ('.jpg', '.jpeg', '.png','.JPG')\n",
    "    return [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(cls_path)\n",
    "            for f in files if f.lower().endswith(valid_ext)]\n",
    "\n",
    "def show_sample_images(data_dir, class_names, num_samples=3):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, cls in enumerate(class_names):\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        img_files = get_all_images_in_class(cls_path)\n",
    "        for j in range(min(num_samples, len(img_files))):\n",
    "            img_path = random.choice(img_files)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(len(class_names), num_samples, i * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{cls}')\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(data_dir, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:04.218670Z",
     "iopub.status.busy": "2025-07-26T18:24:04.218457Z",
     "iopub.status.idle": "2025-07-26T18:24:08.025655Z",
     "shell.execute_reply": "2025-07-26T18:24:08.024968Z",
     "shell.execute_reply.started": "2025-07-26T18:24:04.218653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                try:\n",
    "                    with Image.open(os.path.join(root, img_file)) as img:\n",
    "                        image_sizes.append(img.size)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "# Plot distribution of image sizes\n",
    "widths, heights = zip(*image_sizes)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=30, color='teal')\n",
    "plt.title('Image Width Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=30, color='orange')\n",
    "plt.title('Image Height Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:08.026611Z",
     "iopub.status.busy": "2025-07-26T18:24:08.026427Z",
     "iopub.status.idle": "2025-07-26T18:24:08.605491Z",
     "shell.execute_reply": "2025-07-26T18:24:08.604757Z",
     "shell.execute_reply.started": "2025-07-26T18:24:08.026596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "corrupted_images = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(root, img_file))\n",
    "                    img.verify()\n",
    "                except Exception:\n",
    "                    corrupted_images.append(os.path.join(root, img_file))\n",
    "\n",
    "print(f\"Found {len(corrupted_images)} corrupted images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:08.606594Z",
     "iopub.status.busy": "2025-07-26T18:24:08.606328Z",
     "iopub.status.idle": "2025-07-26T18:24:08.786248Z",
     "shell.execute_reply": "2025-07-26T18:24:08.785624Z",
     "shell.execute_reply.started": "2025-07-26T18:24:08.606570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aspect_ratios = [w / h for (w, h) in image_sizes]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(aspect_ratios, bins=30, color='slateblue')\n",
    "plt.title('Aspect Ratio Distribution')\n",
    "plt.xlabel('Aspect Ratio (width / height)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:08.787526Z",
     "iopub.status.busy": "2025-07-26T18:24:08.786983Z",
     "iopub.status.idle": "2025-07-26T18:24:12.598750Z",
     "shell.execute_reply": "2025-07-26T18:24:12.597725Z",
     "shell.execute_reply.started": "2025-07-26T18:24:08.787506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "brightness = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                if count >= 50: break  # Limit to 50 images per class\n",
    "                img = cv2.imread(os.path.join(root, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    brightness.append((cls, img.mean()))\n",
    "                    count += 1\n",
    "\n",
    "\n",
    "brightness_df = pd.DataFrame(brightness, columns=[\"class\", \"brightness\"])\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=brightness_df, x=\"class\", y=\"brightness\")\n",
    "plt.title(\"Image Brightness per Class\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:12.600103Z",
     "iopub.status.busy": "2025-07-26T18:24:12.599829Z",
     "iopub.status.idle": "2025-07-26T18:24:17.375834Z",
     "shell.execute_reply": "2025-07-26T18:24:17.375199Z",
     "shell.execute_reply.started": "2025-07-26T18:24:12.600084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "color_stats = {cls: [] for cls in class_names}\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if count >= 50: break\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(root, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    mean_color = cv2.mean(img)[:3]  # BGR\n",
    "                    color_stats[cls].append(mean_color[::-1])  # RGB\n",
    "                    count += 1\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "df_color = []\n",
    "for cls, colors in color_stats.items():\n",
    "    for r, g, b in colors:\n",
    "        df_color.append([cls, r, g, b])\n",
    "\n",
    "df_color = pd.DataFrame(df_color, columns=['class', 'R', 'G', 'B'])\n",
    "\n",
    "# Mean RGB\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(data=df_color.groupby(\"class\").mean(numeric_only=True).reset_index().melt(id_vars=\"class\"),\n",
    "            x=\"class\", y=\"value\", hue=\"variable\")\n",
    "plt.title(\"Average RGB per Class\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Mean Pixel Intensity\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:17.376963Z",
     "iopub.status.busy": "2025-07-26T18:24:17.376689Z",
     "iopub.status.idle": "2025-07-26T18:24:23.210684Z",
     "shell.execute_reply": "2025-07-26T18:24:23.209918Z",
     "shell.execute_reply.started": "2025-07-26T18:24:17.376930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sharpness = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if count >= 50: break\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img = cv2.imread(os.path.join(root, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    sharpness_value = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "                    sharpness.append((cls, sharpness_value))\n",
    "                    count += 1\n",
    "\n",
    "sharpness_df = pd.DataFrame(sharpness, columns=[\"class\", \"sharpness\"])\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=sharpness_df, x=\"class\", y=\"sharpness\")\n",
    "plt.title(\"Image Sharpness per Class\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:23.211582Z",
     "iopub.status.busy": "2025-07-26T18:24:23.211386Z",
     "iopub.status.idle": "2025-07-26T18:24:26.208457Z",
     "shell.execute_reply": "2025-07-26T18:24:26.207685Z",
     "shell.execute_reply.started": "2025-07-26T18:24:23.211566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def image_std(img):\n",
    "    return np.std(img)\n",
    "\n",
    "variability = []\n",
    "\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls)\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(cls_path):\n",
    "        for img_file in files:\n",
    "            if count >= 30: break\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img = cv2.imread(os.path.join(root, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    variability.append((cls, image_std(img)))\n",
    "                    count += 1\n",
    "\n",
    "var_df = pd.DataFrame(variability, columns=[\"class\", \"std\"])\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=var_df, x=\"class\", y=\"std\")\n",
    "plt.title(\"Visual Variability (Standard Deviation) per Class\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Size & Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:26.209578Z",
     "iopub.status.busy": "2025-07-26T18:24:26.209323Z",
     "iopub.status.idle": "2025-07-26T18:24:33.359795Z",
     "shell.execute_reply": "2025-07-26T18:24:33.359039Z",
     "shell.execute_reply.started": "2025-07-26T18:24:26.209557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:33.360911Z",
     "iopub.status.busy": "2025-07-26T18:24:33.360602Z",
     "iopub.status.idle": "2025-07-26T18:24:33.366674Z",
     "shell.execute_reply": "2025-07-26T18:24:33.365999Z",
     "shell.execute_reply.started": "2025-07-26T18:24:33.360896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class SquarePad:\n",
    "    \"\"\"Pad an image to make it square by reflecting the short side.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        # img is a PIL Image\n",
    "        w, h = img.size\n",
    "        if w == h:\n",
    "            return img\n",
    "        # compute padding on left/right or top/bottom\n",
    "        diff = abs(h - w)\n",
    "        pad1, pad2 = diff // 2, diff - diff // 2\n",
    "        # if width < height, pad left/right; else pad top/bottom\n",
    "        if w < h:\n",
    "            padding = (pad1, 0, pad2, 0)\n",
    "        else:\n",
    "            padding = (0, pad1, 0, pad2)\n",
    "        img = F.to_tensor(img)\n",
    "        return F.pad(img, padding, mode='reflect')\n",
    "\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Pad(padding=10, padding_mode='constant'),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Pixel Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:33.369719Z",
     "iopub.status.busy": "2025-07-26T18:24:33.369520Z",
     "iopub.status.idle": "2025-07-26T18:24:33.404785Z",
     "shell.execute_reply": "2025-07-26T18:24:33.404223Z",
     "shell.execute_reply.started": "2025-07-26T18:24:33.369704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform_norm = transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                      std=[0.229,0.224,0.225])\n",
    "transform_train = transforms.Compose([\n",
    "    *transform_base.transforms,\n",
    "    transform_norm,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggressive Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:33.405745Z",
     "iopub.status.busy": "2025-07-26T18:24:33.405514Z",
     "iopub.status.idle": "2025-07-26T18:24:33.420414Z",
     "shell.execute_reply": "2025-07-26T18:24:33.419740Z",
     "shell.execute_reply.started": "2025-07-26T18:24:33.405724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.2),\n",
    "    transforms.RandomRotation(30),            \n",
    "    transforms.ColorJitter(brightness=0.2,   \n",
    "                           contrast=0.2,\n",
    "                           saturation=0.2,\n",
    "                           hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.ToTensor(),\n",
    "    transform_norm,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:33.421276Z",
     "iopub.status.busy": "2025-07-26T18:24:33.421018Z",
     "iopub.status.idle": "2025-07-26T18:24:33.911462Z",
     "shell.execute_reply": "2025-07-26T18:24:33.910863Z",
     "shell.execute_reply.started": "2025-07-26T18:24:33.421259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "\n",
    "class_names = ['Clean', 'Dusty', 'Bird-drop', 'Electrical-damage', 'Physical-Damage', 'Snow-Covered']\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "y = []\n",
    "\n",
    "for cls_name in class_names:\n",
    "    cls_path = os.path.join(data_dir, cls_name)\n",
    "    for root, _, files in os.walk(cls_path):  # Recursively go through subfolders like 'new'\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                y.append(class_to_idx[cls_name])\n",
    "                \n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=range(6), y=y)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:33.912397Z",
     "iopub.status.busy": "2025-07-26T18:24:33.912118Z",
     "iopub.status.idle": "2025-07-26T18:24:34.025051Z",
     "shell.execute_reply": "2025-07-26T18:24:34.024354Z",
     "shell.execute_reply.started": "2025-07-26T18:24:33.912373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler,Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_dataset = ImageFolder(root=data_dir, transform=transform_train)\n",
    "targets = [sample[1] for sample in full_dataset.samples]\n",
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, val_indices = train_test_split(\n",
    "    indices, test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(\n",
    "    ImageFolder(root=data_dir, transform=transform_aug),  # Now using augmentation\n",
    "    train_indices\n",
    ")\n",
    "\n",
    "val_dataset = Subset(\n",
    "    ImageFolder(root=data_dir, transform=transform_train),\n",
    "    val_indices\n",
    ")\n",
    "\n",
    "train_targets = [full_dataset.samples[i][1] for i in train_indices]\n",
    "class_counts = Counter(train_targets)\n",
    "sample_weights = [1.0 / class_counts[full_dataset.samples[i][1]] for i in train_indices]\n",
    "\n",
    "# Create sampler only for training set\n",
    "sampler = WeightedRandomSampler(\n",
    "    sample_weights,\n",
    "    num_samples=len(train_indices),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:34.026045Z",
     "iopub.status.busy": "2025-07-26T18:24:34.025818Z",
     "iopub.status.idle": "2025-07-26T18:24:43.486657Z",
     "shell.execute_reply": "2025-07-26T18:24:43.485687Z",
     "shell.execute_reply.started": "2025-07-26T18:24:34.026023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Total dataset size: {len(full_dataset)}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "\n",
    "print(\"\\nTraining class distribution:\")\n",
    "train_class_dist = Counter(train_targets)\n",
    "for cls_idx, count in train_class_dist.items():\n",
    "    print(f\"  Class {cls_idx} ({full_dataset.classes[cls_idx]}): {count} samples\")\n",
    "\n",
    "print(\"\\nValidation class distribution:\")\n",
    "val_targets = [full_dataset.samples[i][1] for i in val_indices]\n",
    "val_class_dist = Counter(val_targets)\n",
    "for cls_idx, count in val_class_dist.items():\n",
    "    print(f\"  Class {cls_idx} ({full_dataset.classes[cls_idx]}): {count} samples\")\n",
    "\n",
    "print(\"\\nSample weights stats (train):\")\n",
    "print(f\"  Min weight: {np.min(sample_weights):.4f}\")\n",
    "print(f\"  Max weight: {np.max(sample_weights):.4f}\")\n",
    "print(f\"  Mean weight: {np.mean(sample_weights):.4f}\")\n",
    "\n",
    "# Optional: show class counts in the weighted sampler\n",
    "print(\"\\nWeightedRandomSampler samples (first 20):\")\n",
    "print(sample_weights[:20])\n",
    "\n",
    "# Optional: peek at one batch from train_loader to check shapes and labels\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "print(f\"\\nOne batch - images shape: {images.shape}, labels: {labels}\")\n",
    "print(f\"Label counts in batch: {Counter(labels.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:43.488651Z",
     "iopub.status.busy": "2025-07-26T18:24:43.488360Z",
     "iopub.status.idle": "2025-07-26T18:24:43.494677Z",
     "shell.execute_reply": "2025-07-26T18:24:43.493922Z",
     "shell.execute_reply.started": "2025-07-26T18:24:43.488605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_weights = None  # Save best weights\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_weights = model.state_dict()  # Save best weights\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:43.496023Z",
     "iopub.status.busy": "2025-07-26T18:24:43.495741Z",
     "iopub.status.idle": "2025-07-26T18:24:43.519857Z",
     "shell.execute_reply": "2025-07-26T18:24:43.519003Z",
     "shell.execute_reply.started": "2025-07-26T18:24:43.495999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    early_stopping = EarlyStopping(patience=7, min_delta=0.001)\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch [{epoch}/{epochs}]\")\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                print(f\"  Batch [{batch_idx + 1}/{len(train_loader)}] - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        print(f\"→ Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"→ Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "            \n",
    "    if early_stopping.best_model_weights is not None:\n",
    "        model.load_state_dict(early_stopping.best_model_weights)\n",
    "        print(\"✅ Restored best model weights.\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:43.521096Z",
     "iopub.status.busy": "2025-07-26T18:24:43.520828Z",
     "iopub.status.idle": "2025-07-26T18:24:43.543275Z",
     "shell.execute_reply": "2025-07-26T18:24:43.542312Z",
     "shell.execute_reply.started": "2025-07-26T18:24:43.521073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def class_report_and_heatmap(model):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    class_names = ['Bird-drop', 'Clean','Dusty', 'Electrical-damage', 'Physical-Damage', 'Snow-Covered']\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=class_names, digits=4))\n",
    "    \n",
    "\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:43.544146Z",
     "iopub.status.busy": "2025-07-26T18:24:43.543896Z",
     "iopub.status.idle": "2025-07-26T18:24:43.553006Z",
     "shell.execute_reply": "2025-07-26T18:24:43.552390Z",
     "shell.execute_reply.started": "2025-07-26T18:24:43.544126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
    "    plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CNN model from strach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:24:43.553955Z",
     "iopub.status.busy": "2025-07-26T18:24:43.553738Z",
     "iopub.status.idle": "2025-07-26T18:24:43.572628Z",
     "shell.execute_reply": "2025-07-26T18:24:43.572043Z",
     "shell.execute_reply.started": "2025-07-26T18:24:43.553941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SolarPanelCNN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(SolarPanelCNN, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:15:11.605691Z",
     "iopub.status.busy": "2025-07-26T19:15:11.605098Z",
     "iopub.status.idle": "2025-07-26T19:30:19.064904Z",
     "shell.execute_reply": "2025-07-26T19:30:19.064224Z",
     "shell.execute_reply.started": "2025-07-26T19:15:11.605666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cmodel = SolarPanelCNN(num_classes=6)\n",
    "optimizer = torch.optim.Adam(cmodel.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "chistory = train_validate(cmodel, train_loader, val_loader, criterion, optimizer, device, epochs=20)\n",
    "plot_training(chistory)\n",
    "class_report_and_heatmap(cmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:26:18.276363Z",
     "iopub.status.busy": "2025-07-26T18:26:18.275665Z",
     "iopub.status.idle": "2025-07-26T18:26:18.283102Z",
     "shell.execute_reply": "2025-07-26T18:26:18.282452Z",
     "shell.execute_reply.started": "2025-07-26T18:26:18.276334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImprovedSolarPanelCNN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ImprovedSolarPanelCNN, self).__init__()\n",
    "        \n",
    "        # Enhanced convolutional blocks\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # Block 1: Larger receptive field\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=2),  # Increased kernel size\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),  # LeakyReLU for better gradient flow\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 2: Increased channels\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 3: Added depth\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # New block 4: Additional layer for better feature extraction\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Global pooling instead of flattening large feature maps\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        # More efficient classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.4),  # Slightly higher dropout for regularization\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:19.066486Z",
     "iopub.status.busy": "2025-07-26T19:30:19.066260Z",
     "iopub.status.idle": "2025-07-26T19:44:44.903963Z",
     "shell.execute_reply": "2025-07-26T19:44:44.903145Z",
     "shell.execute_reply.started": "2025-07-26T19:30:19.066466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cimodel = ImprovedSolarPanelCNN(num_classes=6)\n",
    "\n",
    "optimizer = torch.optim.AdamW(  \n",
    "    cimodel.parameters(),\n",
    "    lr=0.001,      \n",
    "    weight_decay=0.01  \n",
    ")\n",
    "\n",
    "cirhistory = train_validate(cimodel, train_loader, val_loader, criterion, optimizer, device, epochs=20)\n",
    "plot_training(cirhistory)\n",
    "class_report_and_heatmap(cimodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:34:22.687123Z",
     "iopub.status.busy": "2025-07-26T18:34:22.686570Z",
     "iopub.status.idle": "2025-07-26T18:34:22.694517Z",
     "shell.execute_reply": "2025-07-26T18:34:22.693765Z",
     "shell.execute_reply.started": "2025-07-26T18:34:22.687098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "class ResNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Load pre-trained ResNet50\n",
    "        base_model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        # Freeze all layers\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in base_model.named_parameters():\n",
    "            if \"layer4\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Extract feature layers up to the last convolutional block\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-2])\n",
    "\n",
    "        # Custom classification head\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Optional: initialize weights for the classifier\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)      # [batch_size, 2048, H, W]\n",
    "        x = self.pool(x)          # [batch_size, 2048, 1, 1]\n",
    "        x = self.flatten(x)       # [batch_size, 2048]\n",
    "        x = self.classifier(x)    # [batch_size, num_classes]\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:34:31.283674Z",
     "iopub.status.busy": "2025-07-26T18:34:31.283369Z",
     "iopub.status.idle": "2025-07-26T18:48:58.432214Z",
     "shell.execute_reply": "2025-07-26T18:48:58.431367Z",
     "shell.execute_reply.started": "2025-07-26T18:34:31.283651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "rmodel = ResNetCustom(num_classes=num_classes)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.AdamW(rmodel.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "rhistory = train_validate(rmodel, train_loader, val_loader, criterion, optimizer, device, epochs=20)\n",
    "plot_training(rhistory)\n",
    "class_report_and_heatmap(rmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T20:02:40.067762Z",
     "iopub.status.busy": "2025-07-26T20:02:40.067490Z",
     "iopub.status.idle": "2025-07-26T20:02:47.398869Z",
     "shell.execute_reply": "2025-07-26T20:02:47.397693Z",
     "shell.execute_reply.started": "2025-07-26T20:02:40.067741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your class names\n",
    "class_names = ['Bird-drop', 'Clean','Dusty', 'Electrical-damage', 'Physical-Damage', 'Snow-Covered']\n",
    "\n",
    "# Function to predict from a single URL\n",
    "def predict_image_from_url(model, url, transform, class_names, device='cuda'):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = F.softmax(output, dim=1).squeeze()\n",
    "        pred_class = torch.argmax(probs).item()\n",
    "        confidence = probs[pred_class].item()\n",
    "\n",
    "    return img, class_names[pred_class], confidence, probs.cpu().tolist()\n",
    "\n",
    "# Image URLs\n",
    "image_urls = [\n",
    "    \"https://www.kingenergy.com/wp-content/uploads/2023/05/Blog-Image-1.jpg\",\n",
    "    \"https://variatesolar.com/wp-content/uploads/2024/06/Avoid-Costly-Damage-to-Solar-Panels_-Essential-Maintenance-Guide.jpeg\",\n",
    "    \"https://www.drewssolar.com/wp-content/uploads/2025/01/image-asset.jpeg\",\n",
    "    \"https://media.istockphoto.com/id/1350683183/photo/low-angle-view-and-close-up-of-dusty-solar-panel.jpg?s=612x612&w=0&k=20&c=TdC1oicGBkgQb82pvyqoeskUnnoS4Arf8S9qXJNHKwc=\",\n",
    "    \"https://cdn.theatlantic.com/thumbor/4a4JroHlmOrxdAyyMxDrl3YILrw=/1050x0:3750x2700/1080x1080/media/img/mt/2023/10/solar_energy/original.jpg\",\n",
    "    \"https://images.prismic.io/chemitek-website/66b1879c-3cb9-4c8e-a709-994a25f501fb_Newsletter+Cover+%282%29.png?auto=compress,format\",\n",
    "    \"https://regenpower.com/wp-content/uploads/2021/01/solar-damages-1024x576.jpg\",\n",
    "    \"https://5.imimg.com/data5/ANDROID/Default/2023/2/TN/BI/VS/39364804/product-jpeg-500x500.jpg\"\n",
    "]\n",
    "\n",
    "# Predict and store results\n",
    "results = []\n",
    "for url in image_urls:\n",
    "    img, pred_label, confidence, probs = predict_image_from_url(\n",
    "        model=rmodel,\n",
    "        url=url,\n",
    "        transform=transform_train,\n",
    "        class_names=class_names,\n",
    "        device=device\n",
    "    )\n",
    "    results.append((img, pred_label, confidence, probs))\n",
    "\n",
    "# Plot all in a grid\n",
    "n = len(results)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "plt.figure(figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "for i, (img, label, conf, _) in enumerate(results):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{label}\\n({conf:.1%})\", fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3365061,
     "sourceId": 5889548,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
